# robots.txt — getdukka.com
# Autoriser les crawlers légitimes (Google, Bing, etc.)

User-agent: Googlebot
Allow: /
Crawl-delay: 2

User-agent: Bingbot
Allow: /
Crawl-delay: 5

User-agent: facebookexternalhit
Allow: /

User-agent: Twitterbot
Allow: /

User-agent: LinkedInBot
Allow: /

User-agent: WhatsApp
Allow: /

# Bloquer les routes API aux crawlers
User-agent: *
Disallow: /api/
Disallow: /_next/
Disallow: /static/

# Interdire les bots connus pour le scraping agressif
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: BLEXBot
Disallow: /

User-agent: DataForSeoBot
Disallow: /

User-agent: PetalBot
Disallow: /

User-agent: GPTBot
Disallow: /

User-agent: ChatGPT-User
Disallow: /

User-agent: CCBot
Disallow: /

User-agent: anthropic-ai
Allow: /

Crawl-delay: 10

Sitemap: https://getdukka.com/sitemap.xml
